-*- markdown -*-

A WSGI deployment tool - stop being a sysadmin

Introduction
------------

I'm trying to automate deployment and server admin in a sane way. 

By formalizing some project conventions and the server stack, in 
theory large chunks of the deployment process can be automated.
The creation of nodes follows a 'push' model. This means that servers
are commissioned from your client machine. Node interaction and 
commissioning is done with libcloud.

Design notes, terminology
-------------------------

The admin installs kraftwerk on his own computer. The admin 
pushes projects to nodes. Server nodes do not require a kraftwerk 
library. 

Server nodes are referred to by their hostname (can be anything 
because kraftwerk appends your /etc/hosts). 

Projects are referred to by their folder name. Projects root folders 
are virtualenvs. Project root folders contain a Python package which 
would be your webapp.

The kraftwerk cli (command line interface) is path aware. If executed 
inside a project directory it interacts with that project.

Configuration
-------------

Kraftwerk consults a ~/.kraftwerk.yaml file for configuration. This is 
generated from a questionnaire when you first call the kraftwerk cli.
Currently this config is mainly used to interface libcloud drivers.

Secondary configuration is at the project level. Use the kraftwerk 
`init` command to generate a project skeleton and kraftwerk supplies a
default YAML settings file that defines certain behavior of a 
deployed project.

User templates
--------------

Most scripts and files in the project skeleton can be tailored and 
changed by supplying a secondary template directory in the admin 
config. This means you can tweak default parameter and add packages 
to the system install procedure among other things. Currently there 
is no way to change the project skeleton structure although this is a 
possible planned feature.

Project deployment
------------------

Setup and deployment of projects is run from the same non-destructive 
command, `setup-project`. Kraftwerk detects new projects and runs 
setup for each defined service. There is a distinction between 
reloading and restarting services (in the name of availability).

Development vs. stage vs. live
------------------------------

The goal of a stage deployment is to mirror "real-world" application 
conditions to decrease the chances of fucking up once an application 
is deployed to a live server. To this end kraftwerk provides the 
plumbing for a convenient and quick stage test. Secondarily stage 
deployments are useful for client previews and internal testing.

Kraftwerk is agnostic to the development environment. Kraftwerk only 
cares about admin settings, project settings and a Python WSGI 
codebase. Additionally kraftwerk wants to make it easy to bundle 
website data for easy backup and restore (refer to "Services" 
section).

Services
--------

These are databases, key-value storages, cache, queues and certain 
I/O. Services are coupled with a `setup.sh` template script run each 
time a new project requests it's "services".

Services should expect to be interrogated for data per project (in 
bulk). This is for purposes of data migration between nodes and 
backup. Think: SQL dumps and loads.

Quick Start
-----------

Kraftwerk uses libcloud under the hood to commission servers. Cloud 
providers have different APIs which libcloud attempts to abstract as 
much as possible. Some have secret API keys, and some have user/pass 
auth challenges. Kraftwerk thinly veils these differences and simply 
passes user or user/secret credentials to the libcloud provider 
driver.

    $ virtualenv kraftwerk # Assuming virtualenv that includes pip
    $ cd kraftwerk
    $ source bin/activate
    $ pip install -e hg+http://bitbucket.org/jokull/kraftwerk/#egg=kraftwerk
    $ kraftwerk create-node liebe
    > [answer some questions, creates ~/.kraftwerk.yaml]
    $ kraftwerk init calculator
    $ cd calculator
    $ kraftwerk setup-project --node liebe # From within project root

If kraftwerk complains about libcloud missing install it like this:

    pip install -e git+git://github.com/cloudkick/libcloud.git#egg=libcloud

YAML Configuration
------------------

~/.kraftwerk.yaml

+ provider (So far EC2 is tested)
+ user (EC2=Access-Key-ID; Rackspace=Username)
+ secret (EC2=Secret-Access-Key)
+ image_id (EC2=AMI-ID)
+ size_id = (EC2=m1.small)
+ securitygroup (EC2 not required)
+ keyname (EC2 not required)
+ default_node - Don't need to specify --node in CLI
+ templates - Path to templates directory for overwriting

PROJECT/kraftwerk.yaml

+ version - Currently not used
+ domain - Hostname of the main virtualhost
+ aliases - A list of any additional hostnames (HTTP redirect to main)
+ services - List of services the server node will supply to the site
+ workers - gunicorn workers
+ wsgi - module.module:callable to WSGI app
+ packages - space seperated list of packages to pip install

Server Stack
------------

runit, nginx, gunicorn, virtualenv
Python stack: Crypto, PIL, DB drivers

`web` user and a `/web` directory to contain project code and uploads

Consult the `server_setup.sh` script for details.

Static files
------------

Currently kraftwerk automatically serves the project static directory 
with NGINX. Variable static files (user uploads) are handled by the 
`files` service.

    HTTP GET /uploads/file.jpg [/web/project/uploads/file.jpg]
    HTTP GET /static/file.jpg  [/web/project/project/static/file.jpg]

Ideally at least the `static` directory would be served with HTTP 
cache control. Tornado manages expiry of static files quite well by 
doing a checksum of files and appending a query parameter using 
template helpers. This invalidates something like 99% of all caches. 
Kraftwerk leaves this to the application to implement.

Todo
----

+ Service dump and load
+ Logging (possibly with a nice api)
+ libcloud requirement

Installation
------------

virtualenv way:

    virtualenv kraftwerk
    source kraftwerk/bin/activate
    pip install -e hg+http://bitbucket.org/jokull/kraftwerk/#egg=kraftwerk
    kraftwerk init ~/Code/newproject

You may have to install libcloud manually with `python setup.py 
install` (refer to `REQUIREMENTS` file for git location). 

Inspiration
-----------

+ Heroku
+ Silver Lining, markdoc - big chunks of code were taken from these projects

License
-------

No License

Wishlist
--------

I wrote this to address this and scratch this itch. Kept for fun and 
referencing my progress. 

+ Easy to get up and going locally with a Django project - ideally 
one or two commands until there's an activated virtualenv and my 
preferred Django project skeleton is inside TextMate. [DONE]
+ A directory of deployment configuration where I define the caching 
schema, number of workers, staging and live URL's, perhaps super user
accounts. [DONE you define workers a main domain and aliases]
+ Command line tools to load and dump data from _all_ sources 
(PostgreSQL, redis, CouchDB, user uploaded files etc.). Some S3 
backup points perhaps. Something like the Bundle feature in Heroku.
[Support is planned for PostgreSQL, redis and files]
+ Easy migration strategy for scaling to multiple servers.
+ Easy inspection of data and node health. [PLANNED]
+ Easy destroy/create of nodes. [DONE]
+ Easy running one-off commands in the right environment on a remote 
server (think Django syncdb). Or easy dropping into a remote bash 
shell with everything set up for a project.
+ Easy local testing - both quick for code-alt+tab-refresh action and 
a full stack VirtualBox/VMWare deployment. [When libcloud gets a 
VirtualBox driver this will be easy]
+ Easy CDN management at the application level - Environments should 
be aware of how to serve static media. [This might be hard]
+ Easy to venture off the beaten path - this is the enemy of 
automation! [Server scripts and project init skeleton is template 
based - user can define own template directory to overwrite specific
files]
+ Easy to define complimentary processes (like worker daemons). 
[Haven't given this much tought]